# ğŸ›ï¸ Amazon Review Sentiment Analyzer

A machine learning-powered web application that analyzes the sentiment of Amazon product reviews using Natural Language Processing (NLP).

![Python](https://img.shields.io/badge/Python-3.11-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-1.29-red)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3-orange)

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Model Details](#model-details)
- [Screenshots](#screenshots)
- [Deployment](#deployment)
- [Contributing](#contributing)

---

## ğŸ¯ Overview

This project analyzes product reviews and predicts whether they are **positive** or **negative** using a trained Logistic Regression model with TF-IDF features.

**Key Highlights:**
- âœ… 90-95% accuracy on test data
- âœ… Real-time sentiment prediction
- âœ… Beautiful, user-friendly web interface
- âœ… Confidence score display
- âœ… Fast and lightweight

---

## âœ¨ Features

- **Instant Sentiment Analysis**: Get immediate feedback on review sentiment
- **Confidence Scores**: See how confident the model is about its prediction
- **Text Preprocessing**: Automatic cleaning and normalization of input text
- **Visual Feedback**: Color-coded results with emojis (ğŸ˜Š for positive, ğŸ˜  for negative)
- **Example Reviews**: Pre-loaded examples to test the app
- **Responsive Design**: Works on desktop and mobile browsers

---

## ğŸš€ Installation

### Prerequisites

- Python 3.11 or higher
- pip (Python package manager)

### Step 1: Clone the Repository

```bash
git clone https://github.com/yourusername/sentiment-analyzer.git
cd sentiment-analyzer
```

### Step 2: Create Virtual Environment

```bash
python -m venv venv
```

### Step 3: Activate Virtual Environment

**Windows:**
```bash
venv\Scripts\activate
```

**macOS/Linux:**
```bash
source venv/bin/activate
```

### Step 4: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 5: Download NLTK Data

```python
python -c "import nltk; nltk.download('stopwords')"
```

---

## ğŸ’» Usage

### Running the Web App

```bash
streamlit run app.py
```

The app will open automatically in your browser at `http://localhost:8501`

### Using the Model Programmatically

```python
import pickle
import re
from nltk.corpus import stopwords

# Load model and vectorizer
model = pickle.load(open("model.pkl", "rb"))
vec = pickle.load(open("vectorizer.pkl", "rb"))

# Clean text
stop = set(stopwords.words('english'))
def clean(text):
    text = text.lower()
    text = re.sub(r'[^a-z ]', '', text)
    words = [w for w in text.split() if w not in stop]
    return " ".join(words)

# Predict
review = "This product is amazing!"
cleaned = clean(review)
vectorized = vec.transform([cleaned])
sentiment = model.predict(vectorized)[0]
confidence = model.predict_proba(vectorized)[0].max()

print(f"Sentiment: {sentiment} ({confidence*100:.2f}%)")
```

---

## ğŸ“ Project Structure

```
sentiment-analyzer/
â”‚
â”œâ”€â”€ ğŸ“Š DATA FILES
â”‚   â”œâ”€â”€ review dataset.csv              # Original dataset (18.3 MB)
â”‚   â”œâ”€â”€ cleaned_dataset.csv             # After column selection
â”‚   â”œâ”€â”€ labeled_dataset.csv             # With sentiment labels
â”‚   â”œâ”€â”€ final_dataset.csv               # Binary classification
â”‚   â””â”€â”€ processed_dataset.csv           # With cleaned text
â”‚
â”œâ”€â”€ ğŸ¤– MODEL FILES
â”‚   â”œâ”€â”€ model.pkl                       # Trained Logistic Regression
â”‚   â””â”€â”€ vectorizer.pkl                  # TF-IDF Vectorizer
â”‚
â”œâ”€â”€ ğŸ“ SCRIPTS
â”‚   â”œâ”€â”€ app.py                          # Streamlit web app
â”‚   â”œâ”€â”€ sentiment_project.py            # Model training script
â”‚   â””â”€â”€ test_model.py                   # Model testing script
â”‚
â”œâ”€â”€ ğŸ“„ DOCUMENTATION
â”‚   â”œâ”€â”€ README.md                       # This file
â”‚   â”œâ”€â”€ requirements.txt                # Python dependencies
â”‚   â”œâ”€â”€ MODEL_SUMMARY.txt               # Model documentation
â”‚   â””â”€â”€ cleaning_summary.txt            # Data cleaning report
â”‚
â””â”€â”€ ğŸ“¦ venv/                            # Virtual environment
```

---

## ğŸ§  Model Details

### Algorithm
- **Model**: Logistic Regression
- **Max Iterations**: 1000
- **Random State**: 42

### Feature Extraction
- **Method**: TF-IDF (Term Frequency-Inverse Document Frequency)
- **Max Features**: 5000 words
- **Vocabulary Size**: ~5000 unique words

### Dataset
- **Total Reviews**: 1,053
- **Training Set**: 842 reviews (80%)
- **Test Set**: 211 reviews (20%)
- **Classes**:
  - Positive: 977 reviews (92.83%)
  - Negative: 76 reviews (7.17%)

### Performance
- **Accuracy**: ~90-95%
- **Precision**: High for positive class
- **Recall**: High for positive class

### Text Preprocessing
1. Lowercase conversion
2. Special character removal
3. Number removal
4. Stopword removal (179 English stopwords)
5. Tokenization

---

## ğŸ“¸ Screenshots

### Main Interface
![Main Interface](screenshots/main.png)

### Positive Sentiment Result
![Positive Result](screenshots/positive.png)

### Negative Sentiment Result
![Negative Result](screenshots/negative.png)

---

## ğŸŒ Deployment

### Deploy to Streamlit Cloud (Recommended)

1. Push your code to GitHub
2. Go to [Streamlit Cloud](https://streamlit.io/cloud)
3. Sign in with GitHub
4. Click "New app"
5. Select your repository and `app.py`
6. Click "Deploy"

### Deploy to Heroku

1. Create `Procfile`:
```
web: streamlit run app.py --server.port=$PORT
```

2. Deploy:
```bash
heroku create your-app-name
git push heroku main
```

### Deploy to AWS/GCP

Refer to the respective cloud provider's documentation for deploying Streamlit apps.

---

## ğŸ› ï¸ Technologies Used

- **Python 3.11**: Programming language
- **Streamlit**: Web framework
- **scikit-learn**: Machine learning library
- **NLTK**: Natural language processing
- **pandas**: Data manipulation
- **NumPy**: Numerical computing

---

## ğŸ“Š Training Process

### Step 1: Data Collection
- Collected Amazon product reviews dataset (1,597 reviews)

### Step 2: Data Cleaning
- Removed unnecessary columns (kept only text and rating)
- Removed missing values
- Final dataset: 1,177 reviews

### Step 3: Sentiment Labeling
- Rating â‰¥ 4 â†’ Positive
- Rating â‰¤ 2 â†’ Negative
- Rating = 3 â†’ Neutral (removed for binary classification)

### Step 4: Text Preprocessing
- Lowercase conversion
- Special character removal
- Stopword removal
- Text reduction: ~38%

### Step 5: Feature Extraction
- TF-IDF vectorization
- 5000 max features
- Created numerical feature matrix

### Step 6: Model Training
- Train/test split (80/20)
- Logistic Regression with 1000 iterations
- Stratified sampling for balanced sets

### Step 7: Model Evaluation
- Classification report generated
- Confusion matrix analyzed
- Model saved as `model.pkl`

### Step 8: Web App Development
- Streamlit interface created
- Real-time predictions enabled
- Deployed for public use

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**AFSAL AHMED**

- GitHub: [@afsalahmed](https://github.com/yourusername)
- LinkedIn: [Your LinkedIn](https://linkedin.com/in/yourprofile)

---

## ğŸ™ Acknowledgments

- Amazon for the reviews dataset
- scikit-learn for the ML library
- Streamlit for the web framework
- NLTK for NLP tools

---

## ğŸ“§ Contact

For questions or feedback, please reach out at: your.email@example.com

---

**â­ If you found this project helpful, please give it a star!**

---

**Made with â¤ï¸ using Python, Streamlit, and Machine Learning**
